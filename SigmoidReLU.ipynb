{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INM 702 Coursework Code: Task 2\n",
    "## Implementation of Inverted dropout on forward and backward pass\n",
    "### By: Jasveen Kaur and Nikhil Vallakati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary packages for matrix computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to implement inverted dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_drop(self, p, x):\n",
    "        #dropout mask\n",
    "        idropout_mask = (np.random.rand(*x.shape) < p) / p \n",
    "        x *= idropout_mask\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a sample input array (6x3) along with its label (6x1) (same as task 1) to implement forward and backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_set = np.array([[0,1,0],\n",
    "                      [0,0,1],\n",
    "                      [1,0,0],\n",
    "                      [1,1,0],\n",
    "                      [1,1,1],\n",
    "                      [0,1,1],])#Dependent variable\n",
    "labels = np.array([[1,\n",
    "                    0,\n",
    "                    0,\n",
    "                    1,\n",
    "                    1,\n",
    "                    0,]])\n",
    "labels = labels.reshape(6,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward and backward pass on the above defined array, with Relu on input layer, sigmoid on output layer and dropout on the hidden layer of the forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network(object):\n",
    "\n",
    "    def __init__(self, n_hidden, epochs, lr, seed):\n",
    "\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.seed = seed\n",
    "        \n",
    "    #sigmoid activation function   \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    #relu activation function\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x) \n",
    "    \n",
    "    #derivative of relu activation function(element)\n",
    "    def relu_d_element(self, x):\n",
    "        if x > 0:\n",
    "            return 1\n",
    "        elif x <= 0:\n",
    "            return 0\n",
    "    \n",
    "    #derivative of relu activation function(array)\n",
    "    def relu_d_array(self, x):\n",
    "        x[x<=0] = 0\n",
    "        x[x>0] = 1\n",
    "        return x\n",
    "    \n",
    "    #Inverted dropout function definition\n",
    "    def inverted_drop(self, p, x):\n",
    "        idropout_mask = (np.random.rand(*x.shape) < p) / p #dropout mask. Notice /p!\n",
    "        x *= idropout_mask\n",
    "        return x\n",
    "    \n",
    "    #forward pass\n",
    "    def forward_pass(self, X):\n",
    "        \n",
    "        z1 = np.dot(X, self.w1) + self.b1\n",
    "        a1 = self.relu(z1)\n",
    "        a1_drop = self.inverted_drop(0.8,a1) \n",
    "\n",
    "        z_out = np.dot(a1_drop, self.w_out) + self.b_out\n",
    "        a_out = self.sigmoid(z_out)\n",
    "        \n",
    "        return z1, a1, z_out, a_out   \n",
    "\n",
    "    #computing the loss\n",
    "    def compute_cost(self, y_enc, a_out):\n",
    "        term1 = a_out - y_enc \n",
    "        cost = term1.sum()\n",
    "        return cost\n",
    "    \n",
    "    #predicting the output\n",
    "    def predict_out(self, X):\n",
    "        z1, a1,z_out, a_out = self.forward_pass(X)\n",
    "        y_pred = np.argmax(a_out, axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    #calculating the accuracy \n",
    "    def accuracy(self, y, y_pred, X):\n",
    "        return ((np.sum(y.T == y_pred)).astype(np.float) / X.shape[0])\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        \n",
    "        n_output = np.unique(y_train).shape[0]  # number of labels\n",
    "        n_features = X_train.shape[1]\n",
    "\n",
    "         #Initializing the weights\n",
    "        \n",
    "        #hidden layer\n",
    "        self.b1 = np.zeros(self.n_hidden)\n",
    "        self.w1 = self.random.normal(loc=0.0, scale=0.1,size=(n_features, self.n_hidden))\n",
    "        \n",
    "        #output layer\n",
    "        self.b_out = np.zeros(n_output)\n",
    "        self.w_out = self.random.normal(loc=0.0, scale=0.1, size=(self.n_hidden, n_output))\n",
    "        \n",
    "        #training epochs\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            # forward propagation\n",
    "            z1, a1, z_out, a_out = self.forward_pass(X_train)\n",
    "            \n",
    "            # Backpropagation\n",
    "            sigma_out = a_out - labels #sigma_out.sum() = error\n",
    "            relu_derivative = self.relu_d_array(a1)\n",
    "            sigma_h1 = (np.dot(sigma_out, self.w_out.T) * relu_derivative)\n",
    "                \n",
    "            grad_w1 = np.dot(X_train.T, sigma_h1)\n",
    "            grad_b1 = np.sum(sigma_h1, axis=0)\n",
    "\n",
    "            grad_w_out = np.dot(a1.T, sigma_out)\n",
    "            grad_b_out = np.sum(sigma_out, axis=0)\n",
    "\n",
    "            delta_w1 = grad_w1\n",
    "            delta_w_out = grad_w_out  \n",
    "            delta_b1 = grad_b1\n",
    "            delta_b_out = grad_b_out\n",
    "             \n",
    "            #updating the weights\n",
    "            self.w1 -= self.lr * delta_w1\n",
    "            self.w_out -= self.lr * delta_w_out\n",
    "\n",
    "            self.b1 -= self.lr * delta_b1           \n",
    "            self.b_out -= self.lr * delta_b_out\n",
    "\n",
    "        \n",
    "            #evaluating the trained model with updated weights      \n",
    "            z1, a1, z_out, a_out = self.forward_pass(X_train)\n",
    "            \n",
    "            cost = self.compute_cost(y_enc=labels, a_out=a_out)\n",
    "            y_train_pred = self.predict_out(X_train)\n",
    "\n",
    "            train_acc = self.accuracy(y_train, y_train_pred, X_train)\n",
    "            \n",
    "            print(\"epoch:\", i+1)\n",
    "            print(\"Accuracy:\",\"{:.2f}\".format(train_acc*100),\"% ||\",\"loss:\",\"{:.3f}\".format(cost))\n",
    "            \n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the parameters and propagating through one layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Accuracy: 66.67 % || loss: 0.000\n",
      "epoch: 2\n",
      "Accuracy: 83.33 % || loss: 0.012\n",
      "epoch: 3\n",
      "Accuracy: 66.67 % || loss: -0.002\n",
      "epoch: 4\n",
      "Accuracy: 66.67 % || loss: 0.013\n",
      "epoch: 5\n",
      "Accuracy: 83.33 % || loss: -0.019\n",
      "epoch: 6\n",
      "Accuracy: 83.33 % || loss: 0.014\n",
      "epoch: 7\n",
      "Accuracy: 50.00 % || loss: -0.002\n",
      "epoch: 8\n",
      "Accuracy: 66.67 % || loss: 0.019\n",
      "epoch: 9\n",
      "Accuracy: 66.67 % || loss: -0.009\n",
      "epoch: 10\n",
      "Accuracy: 83.33 % || loss: 0.014\n",
      "epoch: 11\n",
      "Accuracy: 66.67 % || loss: 0.026\n",
      "epoch: 12\n",
      "Accuracy: 66.67 % || loss: 0.007\n",
      "epoch: 13\n",
      "Accuracy: 83.33 % || loss: 0.011\n",
      "epoch: 14\n",
      "Accuracy: 83.33 % || loss: 0.005\n",
      "epoch: 15\n",
      "Accuracy: 66.67 % || loss: 0.005\n",
      "epoch: 16\n",
      "Accuracy: 66.67 % || loss: 0.003\n",
      "epoch: 17\n",
      "Accuracy: 83.33 % || loss: 0.018\n",
      "epoch: 18\n",
      "Accuracy: 66.67 % || loss: 0.017\n",
      "epoch: 19\n",
      "Accuracy: 66.67 % || loss: 0.016\n",
      "epoch: 20\n",
      "Accuracy: 83.33 % || loss: 0.010\n",
      "epoch: 21\n",
      "Accuracy: 66.67 % || loss: 0.017\n",
      "epoch: 22\n",
      "Accuracy: 66.67 % || loss: -0.003\n",
      "epoch: 23\n",
      "Accuracy: 66.67 % || loss: 0.012\n",
      "epoch: 24\n",
      "Accuracy: 66.67 % || loss: 0.020\n",
      "epoch: 25\n",
      "Accuracy: 66.67 % || loss: -0.001\n",
      "epoch: 26\n",
      "Accuracy: 83.33 % || loss: 0.027\n",
      "epoch: 27\n",
      "Accuracy: 66.67 % || loss: 0.012\n",
      "epoch: 28\n",
      "Accuracy: 83.33 % || loss: 0.001\n",
      "epoch: 29\n",
      "Accuracy: 100.00 % || loss: 0.009\n",
      "epoch: 30\n",
      "Accuracy: 66.67 % || loss: -0.001\n",
      "epoch: 31\n",
      "Accuracy: 66.67 % || loss: -0.000\n",
      "epoch: 32\n",
      "Accuracy: 66.67 % || loss: -0.006\n",
      "epoch: 33\n",
      "Accuracy: 83.33 % || loss: 0.012\n",
      "epoch: 34\n",
      "Accuracy: 66.67 % || loss: 0.003\n",
      "epoch: 35\n",
      "Accuracy: 66.67 % || loss: 0.004\n",
      "epoch: 36\n",
      "Accuracy: 50.00 % || loss: 0.007\n",
      "epoch: 37\n",
      "Accuracy: 66.67 % || loss: -0.014\n",
      "epoch: 38\n",
      "Accuracy: 66.67 % || loss: 0.019\n",
      "epoch: 39\n",
      "Accuracy: 83.33 % || loss: 0.017\n",
      "epoch: 40\n",
      "Accuracy: 66.67 % || loss: 0.016\n",
      "epoch: 41\n",
      "Accuracy: 66.67 % || loss: 0.008\n",
      "epoch: 42\n",
      "Accuracy: 66.67 % || loss: 0.001\n",
      "epoch: 43\n",
      "Accuracy: 83.33 % || loss: -0.006\n",
      "epoch: 44\n",
      "Accuracy: 66.67 % || loss: 0.005\n",
      "epoch: 45\n",
      "Accuracy: 83.33 % || loss: 0.007\n",
      "epoch: 46\n",
      "Accuracy: 66.67 % || loss: -0.007\n",
      "epoch: 47\n",
      "Accuracy: 66.67 % || loss: 0.004\n",
      "epoch: 48\n",
      "Accuracy: 66.67 % || loss: -0.011\n",
      "epoch: 49\n",
      "Accuracy: 66.67 % || loss: 0.005\n",
      "epoch: 50\n",
      "Accuracy: 66.67 % || loss: -0.009\n",
      "epoch: 51\n",
      "Accuracy: 66.67 % || loss: 0.007\n",
      "epoch: 52\n",
      "Accuracy: 83.33 % || loss: -0.002\n",
      "epoch: 53\n",
      "Accuracy: 66.67 % || loss: -0.005\n",
      "epoch: 54\n",
      "Accuracy: 66.67 % || loss: 0.010\n",
      "epoch: 55\n",
      "Accuracy: 83.33 % || loss: -0.001\n",
      "epoch: 56\n",
      "Accuracy: 66.67 % || loss: 0.008\n",
      "epoch: 57\n",
      "Accuracy: 83.33 % || loss: 0.005\n",
      "epoch: 58\n",
      "Accuracy: 83.33 % || loss: 0.008\n",
      "epoch: 59\n",
      "Accuracy: 66.67 % || loss: 0.016\n",
      "epoch: 60\n",
      "Accuracy: 83.33 % || loss: 0.010\n",
      "epoch: 61\n",
      "Accuracy: 66.67 % || loss: -0.003\n",
      "epoch: 62\n",
      "Accuracy: 83.33 % || loss: -0.003\n",
      "epoch: 63\n",
      "Accuracy: 66.67 % || loss: -0.008\n",
      "epoch: 64\n",
      "Accuracy: 66.67 % || loss: 0.002\n",
      "epoch: 65\n",
      "Accuracy: 66.67 % || loss: 0.009\n",
      "epoch: 66\n",
      "Accuracy: 66.67 % || loss: 0.005\n",
      "epoch: 67\n",
      "Accuracy: 66.67 % || loss: 0.004\n",
      "epoch: 68\n",
      "Accuracy: 66.67 % || loss: 0.008\n",
      "epoch: 69\n",
      "Accuracy: 83.33 % || loss: 0.009\n",
      "epoch: 70\n",
      "Accuracy: 66.67 % || loss: 0.012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.neural_network at 0x25694c0de80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = neural_network(n_hidden=7, epochs=70, lr=0.0005, seed=1)\n",
    "Model.train(X_train=input_set, \n",
    "       y_train=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy fluctuates after a few epochs. It fluctuates with given values: 50, 66.67, 83.33, 100 for 200 epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
